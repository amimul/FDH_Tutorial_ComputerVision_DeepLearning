{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Tutorial : classify digits using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can refer to the original tutorial to get detailed explanations :\n",
    "* [if you never heard of MNIST, softmax, backpropagation](https://www.tensorflow.org/get_started/mnist/beginners)\n",
    "\n",
    "* [if you are a MNIST expert!](https://www.tensorflow.org/get_started/mnist/pros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is an introduction to tensorflow. At the end, given an image of a digit, you will be able to predict which digit it is. You will also understand the principal steps to train a neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install tensorflow in your machine, follow [these steps](https://www.tensorflow.org/install/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np  # library to process arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Import data\n",
    "MNIST is a simple computer vision dataset. It consists of images of handwritten digits.\n",
    "It will be downloaded in your current directory (or loaded from the specified directory if you already downloaded it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### MNIST Dataset structure\n",
    "* training set (55 000) : `mnist.train`\n",
    "* testing set (10 000) : `mnist.testing`\n",
    "* validation set (1 000) : `mnist.validation`\n",
    "\n",
    "Each set contains `images` and `labels`. ( i.e `mnist.train.images`)\n",
    "\n",
    "Labels are `one-hot` vectors. A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In our case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
    "\n",
    "The images have dimensions `28x28`, and will be processed as flatten vectors of dimension 784 (28x28)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of one digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f8ad8d78048>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ad45136a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the library to show the image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Rehape 784 vector to 28x28 image and show in grayscale\n",
    "index = 98\n",
    "plt.imshow(np.reshape(mnist.train.images[index], [28,28]), cmap='gray')\n",
    "plt.title('label = {}'.format(np.argmax(mnist.train.labels[index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_______\n",
    "### Some key TF concepts \n",
    "\n",
    "#### Tensor\n",
    "The central unit of data in TensorFlow is the tensor. A tensor consists of a set of primitive values shaped into an array of any number of dimensions. A tensor's rank is its number of dimensions.\n",
    "\n",
    "#### [Tensorflow's computational graph](https://www.tensorflow.org/get_started/get_started#the_computational_graph)\n",
    "A computational graph is a series of TensorFlow operations arranged into a graph of nodes. Each node takes zero or more tensors as inputs and produces a tensor as an output.\n",
    "There are two separate steps in a Tensorflow programm : \n",
    "* Building the graph\n",
    "* Running the graph\n",
    "\n",
    "To evaluate the nodes, the computational graph must be run within a session. A session encapsulates the control and state of the TensorFlow runtime.\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple model (see perceptron slide in the course)\n",
    "We will build a simple neuron that take an input `x`, multiplies it by some weight `W` and adds a bias `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the neuron\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x` isn't a specific value. It's a `placeholder`, a value that we'll input when we ask TensorFlow to run a computation. We want to be able to input any number of MNIST images, each flattened into a 784-dimensional vector. We represent this as a 2-D tensor of floating-point numbers (`tf.float32`), with a shape `[None, 784]`. (`None` means that a dimension can be of any length.)\n",
    "\n",
    "We also need the weights and biases for our model. A `Variable` is a modifiable tensor that lives in TensorFlow's graph of interacting operations. It can be used and even modified by the computation. For machine learning applications, one generally has the model parameters be `Variable`s.\n",
    "`W` and `b` are initialized with zeros (`tf.zeros`).\n",
    "Notice that `W` has a shape of `[784, 10]` because we want to multiply the 784-dimensional image vectors by it to produce 10-dimensional vectors of evidence for the difference classes. `b` has a shape of `[10]` so we can add it to the output.\n",
    "Then we multiply (`tf.matmul`) the input `x` by the weights `W` and add the bias `b`! (`y = x*W + b`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Softmax regression](https://www.tensorflow.org/get_started/mnist/beginners#softmax_regressions)\n",
    "Every image in MNIST is of a handwritten digit between zero and nine. So there are only ten possible things that a given image can be. We want to be able to look at an image and give the probabilities for it being each digit.\n",
    "\n",
    "This is a classic case where a softmax regression is a natural, simple model. If you want to assign probabilities to an object being one of several different things, softmax is the thing to do, because softmax gives a list of values between 0 and 1 that add up to 1. Even later on, when we train more sophisticated models, the final step will be a layer of softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\text{softmax}(x)_i = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n",
       "with $i$ the class and $j$ the pixel index"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$\\text{softmax}(x)_i = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n",
    "with $i$ the class and $j$ the pixel index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply softmax \n",
    "y_softmax = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now defined (yes, in one line!)\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Training the model](https://www.tensorflow.org/get_started/mnist/beginners#training)\n",
    "In order to train our model, we need to define what it means for the model to be good. Well, actually, in machine learning we typically define the oposite, i.e it means for a model to be bad. This is called the cost, or the loss, and it represents how far off the model is from the desired outcome. We try to minimize that error, and the smaller the error margin, the better the model is.\n",
    "\n",
    "One very common, very nice function to determine the loss of a model is called `cross-entropy`. (see reference for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ crossentropy(y, y') = -\\sum y'\\log(y)$\n",
       "with $y$ the predicted probability distribution and $y'$ the true distribution"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$ crossentropy(y, y') = -\\sum y'\\log(y)$\n",
    "with $y$ the predicted probability distribution and $y'$ the true distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_softmax), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we add a new placeholder `y_` to input the correct answers (i.e the true label).\n",
    "\n",
    "Then we implement the cross-entropy function, with `tf.log` computing the logarithm of each element of `y_softmax`, then each element of `y_`is multiplied by the corresponding element of `tf.log(y_softmax)`. Then `tf.reduce_sum` adds the elements in the second dimension of `y_softmax` (`axis=1` parameter). Finally, `tf.reduce_mean` computes the mean over all the examples in the batch.\n",
    "\n",
    "Because this implementation is numerically instable, we use instead Tensorflow built-in function `tf.nn.softmax_cross_entropy_with_logits` on the unnormalized logits (i.e `y`). This function internally computes the softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So with the built-in tf function we get\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss minimization\n",
    "Because TensorFlow knows the entire graph of your computations, it can automatically use the [backpropagation algorithm](https://colah.github.io/posts/2015-08-Backprop) to efficiently determine how your `Variable`s affect the loss you ask it to minimize. Then it can apply your choice of optimization algorithm to modify the variables and reduce the loss.\n",
    "\n",
    "In our case, we will ask TensorFlow to minimize `cross_entropy` using the [gradient descent algorithm](https://en.wikipedia.org/wiki/Gradient_descent) with a learning rate of 0.5. Gradient descent is a simple procedure, where TensorFlow simply shifts each variable a little bit in the direction that reduces the cost. \n",
    "\n",
    "If you want to try another optimization algorithm just pick one from [these](https://www.tensorflow.org/api_guides/python/train#Optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launching a session\n",
    "We use an `tf.InteractiveSession` (it would be also possible to start a `tf.Session`) and initialize the `Variable`s.\n",
    "\n",
    "And then just start the training by running `train_step` 1000 times. \n",
    "At each step of the loop, we will get a \"batch\" (`batch_xs`, `batch_ys`) of `batch_size` random data points from our training set. We run `train_step` feeding in (via `feed_dict{}`) the batches data to replace the `placeholder`s.\n",
    "\n",
    "Using small batches of random data is called stochastic training -- in this case, stochastic gradient descent. Ideally, we'd like to use all our data for every step of training because that would give us a better sense of what we should be doing, but that's expensive. So, instead, we use a different subset every time. Doing this is cheap and has much of the same benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "batch_size = 100\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Evaluating the model](https://www.tensorflow.org/get_started/mnist/beginners#evaluating_our_model)\n",
    "We'd like to know how well our model performs, so we use for this the test dataset `mnist.test` (which should _never_ be seen during training).\n",
    "\n",
    "We will compare the predicted digit with the label and compute some metrics to estimate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9189\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.argmax` returns the index of the highest entry in a tensor along some axis, so `tf.argmax(y,1)` returns the digit that has been predicted. `tf.equal` compare two elements and outputs `True` when they are equal and `False` otherwise.\n",
    "The accuracy is the mean `tf.reduce_mean` of comparisons between the predicted digit `y` and its label `y_`. \n",
    "The accuracy should be around 92%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's all folks, now you have a (simple) model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Want to try it ? Select an image of digit and feed it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ad8c077b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWTgtRlx0GAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ad8c346a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chose an image to feed\n",
    "index = 140\n",
    "digit_image = mnist.test.images[index]\n",
    "plt.imshow(np.reshape(mnist.test.images[index], [28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = tf.argmax(tf.nn.softmax(y), axis=1)\n",
    "sess.run(prediction, feed_dict={x: digit_image[None]}) # Add None to have a array of shape [1, 784]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to build a bigger model, and achive more than 99% accuracy you can go further on the Notebook\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='input')\n",
    "y_ = tf.placeholder(tf.float32, [None, 10], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Multilayer Convolutional Network](https://www.tensorflow.org/get_started/mnist/pros#build_a_multilayer_convolutional_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create this model, we're going to need to create a lot of weights and biases. One should generally initialize weights with a small amount of noise for symmetry breaking, and to prevent 0 gradients. Since we're using [ReLU]( https://en.wikipedia.org/wiki/Rectifier_(neural_networks) neurons, it is also good practice to initialize them with a slightly positive initial bias to avoid \"dead neurons\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two first functions will create and initialize the weights `weight_variable` and biases `bias_variable`. `conv2d` and `max_pool_2x2` perform 2D convolution and max-pooling 2x2 (which halves the size of the image each time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name=None):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name=None):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First  layer : convolution + max-pooling\n",
    "The first layer will consist of a convolution, followed by max pooling. The convolution will compute 32 features for each 5x5 patch. Its weight tensor will have a shape of `[5, 5, 1, 32]`. The first two dimensions are the patch size (`[5,5]`), the next is the number of input channels ([`1`]), and the last is the number of output channels ([`32`]). We will also have a bias vector with a component for each output channel (of size `[32]` to be able to add it to the weighted input).\n",
    "\n",
    "Before applying the convolution, we need to reshape the flatten 784 vector to get a 28x28 image in order to apply 2D convolution and extend the 2D image to a 4D tensor (final dimension corresponding to the number of color channels).\n",
    "\n",
    "Then we convolve the image with the weights `W1`, add the biases `b1`, apply the ReLU activation and max-pool the result. This results in a tensor of shape `[?, 14, 14, 32]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "with tf.name_scope('layer-1'):\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second layer : convolution + max-pooling\n",
    "Repeat the layer. This time the convolution computes 64 features. The 2x2 max-pooling will reduce the size of the output to `[?, 7, 7, 64]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('layer-2'):\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third layer : densely connected\n",
    "We add a fully-connected layer with 1024 neurons to allow processing on the entire image. We reshape the tensor from the pooling layer into a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('layer-3'):\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last layer : readout\n",
    "Last layer with 10 clasees output to apply the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('layer-readout'):\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Training the model and evaluating the perfomance while training\n",
    "\n",
    "For the training, the loss function is the same as the simple model, but the optimizer algorithm is a more sophisticated one (ADAM). The accuracy computation doesn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time when running the graph, we will use a `tf.Session` rather than `tf.InteractiveSession`. This better separates the process of creating the graph (model specification) and the process of evaluating the graph (model fitting). The tf.Session is created within a `with-block` so that it is automatically destroyed once the block is exited.\n",
    "\n",
    "Also, this time we'll add logging to every 100th iteration in the training process\n",
    "\n",
    "__Be aware that 20 000 training iterations may take a while (possibly up to half an hour), depending on your processor.__\n",
    "\n",
    "The final accuracy should be above 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.9\n",
      "step 200, training accuracy 0.9\n",
      "step 300, training accuracy 0.98\n",
      "step 400, training accuracy 0.94\n",
      "step 500, training accuracy 0.98\n",
      "step 600, training accuracy 0.96\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.98\n",
      "step 900, training accuracy 0.98\n",
      "step 1000, training accuracy 0.94\n",
      "step 1100, training accuracy 1\n",
      "step 1200, training accuracy 1\n",
      "step 1300, training accuracy 0.98\n",
      "step 1400, training accuracy 0.98\n",
      "step 1500, training accuracy 1\n",
      "step 1600, training accuracy 0.96\n",
      "step 1700, training accuracy 0.88\n",
      "step 1800, training accuracy 1\n",
      "step 1900, training accuracy 1\n",
      "test accuracy 0.9812\n"
     ]
    }
   ],
   "source": [
    "training_steps = 2000  # ideally 20'000\n",
    "batch_size = 50\n",
    "evaluation_interval = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(training_steps):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        if i % evaluation_interval == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "To visualize the graph of your model you can run from a terminal `tensorboard --logdir logdir`\n",
    "\n",
    "¨¨Then go to `localhost:6006`\n",
    "\n",
    "__Warning__ execute each cell only once to have a nice graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(logdir='logdir', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
